{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZZZRUuwLCcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFWIuBppG0X_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfE5z3ipG7oZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7d4XxLG-ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    y_true -- true labels, required when we define a loss in Keras, we don't need it in this function.\n",
        "    y_pred -- python list containing three objects:\n",
        "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
        "            positive -- the encodings for the positive images, of shape (None, 128)\n",
        "            negative -- the encodings for the negative images, of shape (None, 128) \n",
        "    \"\"\"\n",
        "    \n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "    \n",
        "    # distance between the anchor and the positive\n",
        "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis = -1)\n",
        "    # distance between the anchor and the negative\n",
        "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis = -1)\n",
        "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw73BvRlIDJy",
        "colab_type": "text"
      },
      "source": [
        "Loading pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGq-BsSVH9d1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcdaSFKWITHI",
        "colab_type": "text"
      },
      "source": [
        "Database to verify with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJx6NeW1IPUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "database = {}\n",
        "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
        "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
        "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
        "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
        "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
        "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
        "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
        "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
        "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
        "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
        "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80MJrNOaJIUj",
        "colab_type": "text"
      },
      "source": [
        "Verification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQER-Bo_Id5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    # encoding for the image\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    \n",
        "    # distance with identity's image\n",
        "    dist = np.linalg.norm(np.subtract(encoding, database[identity]))\n",
        "    \n",
        "    # Open door if dist < 0.7, else don't open\n",
        "    if dist < 0.7 :\n",
        "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"It's not \" + str(identity) + \", please go away\")\n",
        "        door_open = False\n",
        "        \n",
        "    return dist, door_open"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjVX6Bp3J0Wn",
        "colab_type": "text"
      },
      "source": [
        "Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LiuoU7XJLwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "    \"\"\"\n",
        "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
        "\n",
        "    \"\"\" \n",
        "    \n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    \n",
        "    # To find the closest encoding\n",
        "\n",
        "    min_dist = 100\n",
        "    for (name, db_enc) in database.items():\n",
        "        \n",
        "        # Compute distance between the target \"encoding\" and the current db_enc from the database\n",
        "        dist = np.linalg.norm(np.subtract(encoding, db_enc))\n",
        "\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    if min_dist > 0.7:\n",
        "        print(\"Not in the database.\")\n",
        "    else:\n",
        "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
        "        \n",
        "    return min_dist, identity"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}